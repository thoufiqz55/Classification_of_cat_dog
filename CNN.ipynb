{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1u5nPeoi0Ug8D6m-Ouo4Kz_rEAXMwOLR8",
      "authorship_tag": "ABX9TyMArHU3y9oQvPK40xPM3/uH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thoufiqz55/Classification_of_cat_dog/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTo-sMtI0_7h"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "J3frhrm81cGo",
        "outputId": "2ffd332f-7624-45ea-f227-0fedac3e7885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.8.0'"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dSOAtY-11hS8",
        "outputId": "661d979f-0c1a-48bf-a9dc-7136177d80b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/data')"
      ],
      "metadata": {
        "id": "9PwvU2421p_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a3ffb99-82ef-4240-9d15-85f56640716a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/data; to attempt to forcibly remount, call drive.mount(\"/content/data\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/data/MyDrive/Image Classification (Cats vs Dogs)')"
      ],
      "metadata": {
        "id": "jVt4Bgfm0Ii9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/Image Classification (Cats vs Dogs)/training_set',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2Gw122_0h0g",
        "outputId": "8c079921-1b89-4f34-840c-94acd37bef72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/Image Classification (Cats vs Dogs)/test_set',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxoGpgBW8Q2H",
        "outputId": "18b409a3-1e5a-40fa-8997-a8b1e64a887a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "dl1GjhsG8jBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\n"
      ],
      "metadata": {
        "id": "cXbFvRT18pfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "GB2NzePP9BkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "NHnh3KUG9Nt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
      ],
      "metadata": {
        "id": "q6lqnURc9caO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n"
      ],
      "metadata": {
        "id": "igI87Njh9eyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtQLQe2-9jBL",
        "outputId": "796a434b-02e4-413d-913d-d53778c26b05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 60, 60, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 30, 30, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 28800)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               3686528   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,696,801\n",
            "Trainable params: 3,696,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "46QuZrU09khU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ColeU8cA90Mt",
        "outputId": "e713014e-9a3f-49f0-b924-71dc912ce579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "125/125 [==============================] - 1274s 10s/step - loss: 0.6855 - accuracy: 0.5690 - val_loss: 0.6414 - val_accuracy: 0.6460\n",
            "Epoch 2/25\n",
            "125/125 [==============================] - 63s 507ms/step - loss: 0.6372 - accuracy: 0.6482 - val_loss: 0.6344 - val_accuracy: 0.6490\n",
            "Epoch 3/25\n",
            "125/125 [==============================] - 66s 529ms/step - loss: 0.6167 - accuracy: 0.6665 - val_loss: 0.6612 - val_accuracy: 0.6040\n",
            "Epoch 4/25\n",
            "125/125 [==============================] - 66s 525ms/step - loss: 0.5861 - accuracy: 0.6905 - val_loss: 0.5681 - val_accuracy: 0.7030\n",
            "Epoch 5/25\n",
            "125/125 [==============================] - 65s 521ms/step - loss: 0.5476 - accuracy: 0.7285 - val_loss: 0.5641 - val_accuracy: 0.7100\n",
            "Epoch 6/25\n",
            "125/125 [==============================] - 66s 525ms/step - loss: 0.5239 - accuracy: 0.7437 - val_loss: 0.5712 - val_accuracy: 0.7050\n",
            "Epoch 7/25\n",
            "125/125 [==============================] - 66s 526ms/step - loss: 0.4857 - accuracy: 0.7613 - val_loss: 0.5703 - val_accuracy: 0.7310\n",
            "Epoch 8/25\n",
            "125/125 [==============================] - 65s 521ms/step - loss: 0.4806 - accuracy: 0.7620 - val_loss: 0.5810 - val_accuracy: 0.7180\n",
            "Epoch 9/25\n",
            "125/125 [==============================] - 66s 523ms/step - loss: 0.4527 - accuracy: 0.7930 - val_loss: 0.5627 - val_accuracy: 0.7230\n",
            "Epoch 10/25\n",
            "125/125 [==============================] - 65s 523ms/step - loss: 0.4357 - accuracy: 0.8008 - val_loss: 0.5484 - val_accuracy: 0.7320\n",
            "Epoch 11/25\n",
            "125/125 [==============================] - 66s 525ms/step - loss: 0.4194 - accuracy: 0.8020 - val_loss: 0.5704 - val_accuracy: 0.7290\n",
            "Epoch 12/25\n",
            "125/125 [==============================] - 66s 529ms/step - loss: 0.3846 - accuracy: 0.8303 - val_loss: 0.5524 - val_accuracy: 0.7550\n",
            "Epoch 13/25\n",
            "125/125 [==============================] - 66s 527ms/step - loss: 0.3778 - accuracy: 0.8357 - val_loss: 0.5787 - val_accuracy: 0.7380\n",
            "Epoch 14/25\n",
            "125/125 [==============================] - 64s 515ms/step - loss: 0.3455 - accuracy: 0.8505 - val_loss: 0.6304 - val_accuracy: 0.7430\n",
            "Epoch 15/25\n",
            "125/125 [==============================] - 63s 502ms/step - loss: 0.3306 - accuracy: 0.8555 - val_loss: 0.5817 - val_accuracy: 0.7610\n",
            "Epoch 16/25\n",
            "125/125 [==============================] - 63s 501ms/step - loss: 0.3056 - accuracy: 0.8700 - val_loss: 0.6267 - val_accuracy: 0.7390\n",
            "Epoch 17/25\n",
            "125/125 [==============================] - 63s 500ms/step - loss: 0.2742 - accuracy: 0.8863 - val_loss: 0.6692 - val_accuracy: 0.7610\n",
            "Epoch 18/25\n",
            "125/125 [==============================] - 63s 500ms/step - loss: 0.2630 - accuracy: 0.8898 - val_loss: 0.6849 - val_accuracy: 0.7500\n",
            "Epoch 19/25\n",
            "125/125 [==============================] - 63s 501ms/step - loss: 0.2409 - accuracy: 0.9075 - val_loss: 0.6758 - val_accuracy: 0.7610\n",
            "Epoch 20/25\n",
            "125/125 [==============================] - 63s 502ms/step - loss: 0.2396 - accuracy: 0.9047 - val_loss: 0.7045 - val_accuracy: 0.7340\n",
            "Epoch 21/25\n",
            "125/125 [==============================] - 63s 504ms/step - loss: 0.2177 - accuracy: 0.9135 - val_loss: 0.6751 - val_accuracy: 0.7450\n",
            "Epoch 22/25\n",
            "125/125 [==============================] - 63s 502ms/step - loss: 0.2018 - accuracy: 0.9172 - val_loss: 0.7579 - val_accuracy: 0.7470\n",
            "Epoch 23/25\n",
            "125/125 [==============================] - 63s 502ms/step - loss: 0.1778 - accuracy: 0.9305 - val_loss: 0.6818 - val_accuracy: 0.7600\n",
            "Epoch 24/25\n",
            "125/125 [==============================] - 63s 501ms/step - loss: 0.1635 - accuracy: 0.9342 - val_loss: 0.7360 - val_accuracy: 0.7560\n",
            "Epoch 25/25\n",
            "125/125 [==============================] - 63s 500ms/step - loss: 0.1770 - accuracy: 0.9360 - val_loss: 0.8637 - val_accuracy: 0.7320\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f92f24bec90>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('//content/photo-1615789591457-74a63395c990', target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = cnn.predict(test_image)\n",
        "training_set.class_indices\n",
        "if result[0][0] == 1:\n",
        "    prediction = 'dog'\n",
        "else:\n",
        "    prediction = 'cat'"
      ],
      "metadata": {
        "id": "vSggwBVu93KE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUS0-Gy1LBQP",
        "outputId": "aa6110e6-0779-41e1-ff06-80f20176f957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat\n"
          ]
        }
      ]
    }
  ]
}